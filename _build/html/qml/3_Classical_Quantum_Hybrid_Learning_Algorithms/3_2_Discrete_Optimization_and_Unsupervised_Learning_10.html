<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Clustering by Quantum Optimization &mdash; Daniel Mo Houshmand</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sphinx-thebe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/exercise.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/QDaria.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mo_addmination.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/QDaria.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mo_addmination.css" type="text/css" />
    <link rel="canonical" href="https://qdaria.com/qml/3_Classical_Quantum_Hybrid_Learning_Algorithms/3_2_Discrete_Optimization_and_Unsupervised_Learning_10.html" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
        <script src="../../_static/tabs.js"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../../_static/togglebutton.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script src="../../_static/design-tabs.js"></script>
        <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
        <script async="async" src="../../_static/sphinx-thebe.js"></script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Kernel Methods" href="3_3_Kernel_Methods_11.html" />
    <link rel="prev" title="Encoding Classical Information" href="3_1_Discrete_Optimization_And_Ensemble_Learning_Ecoding_Classical_Inforfmation_9.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/D62.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quantum Computers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../quantum_computers/0_QC/0_quantum_computers.html">1. Into the Hardware of Quantum Computers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantum_computers/1_spin/1_0_spin.html">2. Spin-Based and Molecular Approaches</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantum_computers/3_superconducting/3_0_superconducting.html">3. jupytext:
formats: md:myst
text_representation:
extension: .md
format_name: myst
format_version: 0.13
jupytext_version: 1.11.5
kernelspec:
display_name: Python 3
language: python
name: python3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantum_computers/3_superconducting/3_0_superconducting.html#superconductivity">4. Superconductivity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantum_computers/4_topological_qubits/4_0_topological.html">5. Topological Qubits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantum_computers/5_adiabatic_hybrid/5_0_adiabatic.html">6. Adiabatic Quantum Computers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantum_computers/6_semiconductors/6_0_semicunductors.html">7. Semiconductor-based qubits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantum_computers/7_trapped/7_0_trapped.html">8. Trapped Particles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantum_computers/8_photonic/8_0_photonic.html">9. Photonic and Optical Approaches</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quantum Machine Learning</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../1_quantum_systems/1_quantum_systems.html">Quantum Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_quantum_computations/2_quantum_computations.html">Quantum Computations</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="3_Classical_Quantum_Hybrid_Learning_Algorithms.html">Classical Quantum Hybrid Learning Algorithms</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="3_1_Discrete_Optimization_And_Ensemble_Learning_Ecoding_Classical_Inforfmation_9.html">Encoding Classical Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_1_Discrete_Optimization_And_Ensemble_Learning_Ecoding_Classical_Inforfmation_9.html#loss-functions-and-regularization">Loss Functions and Regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_1_Discrete_Optimization_And_Ensemble_Learning_Ecoding_Classical_Inforfmation_9.html#ensemble-learning">Ensemble Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_1_Discrete_Optimization_And_Ensemble_Learning_Ecoding_Classical_Inforfmation_9.html#ensemble-methods">Ensemble methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_1_Discrete_Optimization_And_Ensemble_Learning_Ecoding_Classical_Inforfmation_9.html#qboost">Qboost</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_1_Discrete_Optimization_And_Ensemble_Learning_Ecoding_Classical_Inforfmation_9.html#more-qboost">More QBoost</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_1_Discrete_Optimization_And_Ensemble_Learning_Ecoding_Classical_Inforfmation_9.html#solving-by-qaoa">Solving by QAOA</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_1_Discrete_Optimization_And_Ensemble_Learning_Ecoding_Classical_Inforfmation_9.html#references">References</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Clustering by Quantum Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mapping-clustering-to-discrete-optimization">Mapping clustering to discrete optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#solving-the-max-cut-problem-by-qaoa">Solving the max-cut problem by QAOA</a></li>
<li class="toctree-l2"><a class="reference internal" href="#solving-the-max-cut-problem-by-annealing">Solving the max-cut problem by annealing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_3_Kernel_Methods_11.html">Kernel Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_3_Kernel_Methods_11.html#an-inference">An Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_3_Kernel_Methods_11.html#thinking-backward-learning-methods-based-on-what-the-hardware-can-do">Thinking backward: learning methods based on what the hardware can do</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_3_Kernel_Methods_11.html#a-natural-kernel-on-a-shallow-circuit">A natural kernel on a shallow circuit</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_3_Kernel_Methods_11.html#references">References</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html">An Inference Circuit</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html#tror-ikke-skal-vaere-her-men-i-11">(Tror ikke skal være her men i (11))</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html#probalistic-graphical-model">Probalistic Graphical Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html#gfx">GFX!!!??</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html#probabilistic-graphical-models">Probabilistic graphical models</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html#optimization-and-sampling-pgms">Optimization and Sampling PGMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html#se-igjen-i-lyx-husk-implementering-og-plots">Se igjen i lyx (Husk implementering og plots)</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html#se-bildet-grafen-pa-lyx">Se bildet grafen på lyx</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html#boltzmann-machines">Boltzmann machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html#references">References</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_4_Training_Probabilistic_Graphical_Models_12.html#se-eksamen">SE EKSAMEN!!!</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../4_Coherent_Learning_Protocols/4_Coherent_Learning_Protocols.html">Coherent Learning Protocols</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_quantumkernels/5_quantumkernels.html">Quantum Kernels</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Python</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="3_Classical_Quantum_Hybrid_Learning_Algorithms.html">Classical Quantum Hybrid Learning Algorithms</a></li>
      <li class="breadcrumb-item active">Clustering by Quantum Optimization</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/qml/3_Classical_Quantum_Hybrid_Learning_Algorithms/3_2_Discrete_Optimization_and_Unsupervised_Learning_10.ipynb" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="clustering-by-quantum-optimization">
<h1>Clustering by Quantum Optimization<a class="headerlink" href="#clustering-by-quantum-optimization" title="Permalink to this headline"></a></h1>
<p>We looked at one particular problem that you can solve by mapping it to an Ising model. This was a supervised problem, and it’s very difficult to be competitive with supervised models on classical computers because that’s exactly where deep learning excels at. An astounding point would be for quantum machine learning is that you can solve problems which remain hard in machine learning. So one of these is unsupervised learning. So deep learning and many other machine learning approaches have been making advances when it remains a difficult problem. So what happens here</p>
<div class="math notranslate nohighlight">
\[\{x_{i}\}_{i=1}^{N}\qquad x_{i}\in\mathbb{R}^{d}\]</div>
<p>is that we are given a couple of points in some high dimensional space, but we do not get any prior information about whether they belong to a certain class or how they cluster in this structure. So for instance, we have to figure out what the labels would be and how we would assign those labels.</p>
<div class="math notranslate nohighlight">
\[P(y\mid x)\rightarrow\text{discriminative}\]</div>
<div class="math notranslate nohighlight">
\[P(y\mid x)\rightarrow\text{generative}\]</div>
<p>This is a discriminative, unsupervised learning problem. And we can also ask the question what is the distribution of these points. Can we generate new points on this high dimensional manifold? That would be a generative problem. So let’s look at clustering in this lecture.</p>
<p>So in clustering, you have these high dimensional points, and you want to identify these clumps of points that somehow belong together. So if there’s a nice separation, then a very simple learning algorithm called K means can identify these clusters. So in K means, you identify some center point of these locations. And then you assign clusters based on the proximity to this central point. This idea breaks down where the density matters. So for instance, in this case, K means clustering would assign these points to the green cluster, which is not correct. So what you could do instead, you can follow the density and assign points to the same cluster if they’re connected in some topological way. And same thing for these green dots. So that’s density-based clustering. So there are a couple of ways of doing it, and there’s no clear winner. So here’s one way of doing it by a quantum computer. We can think about calculating the gram matrix, the distance between every single point in the sample that we are given. So we fill this gram matrix</p>
<div class="math notranslate nohighlight">
\[K_{ix}=d(x_{i},x_{j})\]</div>
<p>with the distances between individual points. This is a symmetric matrix because the distance function is symmetric. Now if you have the gram matrix, that actually defines a weighted graph. So the points of the graph will be the data instances. We can label them by the data instances. And the edges connecting them will be weighted by the corresponding distance between the points. And now we can ask, OK, so what’s the highest value of a cut going through this graph. So we will now want to separate this graph in two a way that the value of this cut is maximal. So that would identify these two maximally separate clusters that we’re actually looking for, looking at the overall global topology of the graph as opposed to some local heuristic. So we can do that. So say this part of the graph is called V1. So everything on this side of the cut is V1. And this is V2. Then the value of the cut is defined by the distances that cross the cut. So this will be a distance between all the points that line the two sides of the cut.</p>
<p>$<span class="math notranslate nohighlight">\(\sum_{i\in V_{1},j\in V_{2}}\underbrace{d(x_{i},x_{j})}_{w_{ij}}=\frac{1}{4}\sum w_{ij}+\sum w_{ij}\sigma_{i}\sigma_{j}\)</span>$ So I’m going to call this as a WIJ value. So we can expand the same thing in the following form. So imagine that you have values on the same side of the graph. So if– now let’s define a sigma i value as minus 1 if the corresponding xi point is in v1– so on this side of the partition. And it’s going to be plus 1 if the point is in v2. So if you have something on the same side and you calculate the product of this, as I did here, that’s going to give you a plus 1. So that’s going to cancel out in this equation. So it’s actually not going to matter at all. So that looks good. So there’s– these two look equal in that sense. And if they belong to two separate sides, then they will have a negative value. So they will add. And it’s a symmetric matrix. So right now you have to normalize with four. So this gives you the cost of the cut, and this is what you want to maximize. And now when you look at it, this is exactly an Ising model because here, you have your spin variables taking plus 1, minus 1 values. Here, you have the coupling strength, and you have some constant offset. And that’s it. Now you can use Quantum Annealing, or QAOA, or any other quantum optimization subroutine that you have available and solve this problem.</p>
<p>Check</p>
<p>• In an unsupervised learning problem…</p>
<p>– Labels are not provided</p>
<p>• Calculating the Gram or kernel matrix <span class="math notranslate nohighlight">\(K_{ix}=d(x_{i},x_{j})\)</span> …</p>
<p>– Has <span class="math notranslate nohighlight">\(O(N^{2})\)</span> computational complexity</p>
<p>• You are given a graph with strictly positive weights on its edges. A maximum cut…</p>
<p>– Takes exponentially many steps to find in the number of graph nodes.</p>
<p>Unsupervised learning means a lack of labels: we are looking for structure in the data, without having an <em>a priori</em> intuition what that structure might be. A great example is clustering, where the goal is to identify instances that clump together in some high-dimensional space. Unsupervised learning in general is a harder problem. Deep learning revolutionized supervised learning and it had made significant advances in unsupervised learning, but there remains plenty of room for improvement. In this notebook, we look at how we can map an unsupervised learning problem to graph optimization, which in turn we can solve on a quantum computer.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="mapping-clustering-to-discrete-optimization">
<h1>Mapping clustering to discrete optimization<a class="headerlink" href="#mapping-clustering-to-discrete-optimization" title="Permalink to this headline"></a></h1>
<p>Assume that we have some points <span class="math notranslate nohighlight">\(\{x_i\}_{i=1}^N\)</span> lying in some high-dimensional space <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>. How do we tell which ones are close to one another and which ones are distant? To get some intuition, let’s generate a simple dataset with two distinct classes. The first five instances will belong to class 1, and the second five to class 2:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">n_instances</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">class_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_instances</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">/</span><span class="mi">5</span>
<span class="n">class_2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_instances</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">/</span><span class="mi">5</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">class_1</span><span class="p">,</span> <span class="n">class_2</span><span class="p">))</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;red&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_instances</span><span class="o">//</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;green&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_instances</span><span class="o">//</span><span class="mi">2</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">zticks</span><span class="o">=</span><span class="p">[])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x138259d00&gt;
</pre></div>
</div>
<img alt="../../_images/739c8061fa4d92245c059258624f4b62484e0de5cd1b99bf979af4a4766f026c.png" src="../../_images/739c8061fa4d92245c059258624f4b62484e0de5cd1b99bf979af4a4766f026c.png" />
</div>
</div>
<p>The high-dimensional space is endowed with some measure of distance, the Euclidean distance being the simplest case. We can calculate all pairwise distances between the data points:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_instances</span><span class="p">,</span> <span class="n">n_instances</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">n_instances</span><span class="p">)]</span><span class="o">*</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>This matrix is sometimes called the Gram or the kernel matrix. The Gram matrix contains a fair bit of information about the topology of the points in the high-dimensional space, but it is not easy to see. We can think of the Gram matrix as the weighted adjacency matrix of a graph: two nodes represent two data instances. Their distance as contained in the Gram matrix is the weight on the edge that connects them. If the distance is zero, they are not connected by an edge. In general, this is a dense graph with many edges – sparsity can be improved by a distance function that gets exponentially smaller.</p>
<p>What can we do with this graph to find the clusters? We could look for the max-cut, that is, the collection of edges that would split the graph in exactly two if removed, while maximizing the total weight of these edges [<span class="xref myst">1</span>]. This is a well-known NP-hard problem, but it also very naturally maps to an Ising model.</p>
<p>The spin variables <span class="math notranslate nohighlight">\(\sigma_i \in \{-1, +1\}\)</span> take on value <span class="math notranslate nohighlight">\(\sigma_i = +1\)</span> if a data instance is in cluster 1 (nodes <span class="math notranslate nohighlight">\(V_1\)</span> in the graph), and <span class="math notranslate nohighlight">\(\sigma_i = -1\)</span> if the data instance is in cluster 2 (nodes <span class="math notranslate nohighlight">\(V_2\)</span> in the graph). The cost of a cut is</p>
<div class="math notranslate nohighlight">
\[
\sum_{i\in V_1, j\in V_2} w_{ij}
\]</div>
<p>Let us assume a fully connected graph. Then, accounting for the symmetry of the adjacency matrix, we can expand this as
$<span class="math notranslate nohighlight">\(
\frac{1}{4}\sum_{i, j} w_{ij} - \frac{1}{4} \sum_{i, j} w_{ij} \sigma_i \sigma_j
\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(
= \frac{1}{4}\sum_{i, j\in V} w_{ij} (1- \sigma_i \sigma_j).
\)</span>$</p>
<p>By taking the negative of this, we can directly solve the problem by a quantum optimizer.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="solving-the-max-cut-problem-by-qaoa">
<h1>Solving the max-cut problem by QAOA<a class="headerlink" href="#solving-the-max-cut-problem-by-qaoa" title="Permalink to this headline"></a></h1>
<p>Most quantum computing frameworks have convenience functions defined for common graph optimization algorithms, and max-cut is a staple. This reduces our task to importing the relevant functions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">qiskit.aqua</span> <span class="kn">import</span> <span class="n">get_aer_backend</span><span class="p">,</span> <span class="n">QuantumInstance</span>
<span class="kn">from</span> <span class="nn">qiskit.aqua.algorithms</span> <span class="kn">import</span> <span class="n">QAOA</span>
<span class="kn">from</span> <span class="nn">qiskit.aqua.components.optimizers</span> <span class="kn">import</span> <span class="n">COBYLA</span>
<span class="kn">from</span> <span class="nn">qiskit.aqua.translators.ising</span> <span class="kn">import</span> <span class="n">max_cut</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">qiskit.aqua</span> <span class="kn">import</span> <span class="n">get_aer_backend</span><span class="p">,</span> <span class="n">QuantumInstance</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">from</span> <span class="nn">qiskit.aqua.algorithms</span> <span class="kn">import</span> <span class="n">QAOA</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">qiskit.aqua.components.optimizers</span> <span class="kn">import</span> <span class="n">COBYLA</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;qiskit.aqua&#39;
</pre></div>
</div>
</div>
</div>
<p>Setting <span class="math notranslate nohighlight">\(p=1\)</span> in the QAOA algorithm, we can initialize it with the max-cut problem.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qubit_operators</span><span class="p">,</span> <span class="n">offset</span> <span class="o">=</span> <span class="n">max_cut</span><span class="o">.</span><span class="n">get_max_cut_qubitops</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">COBYLA</span><span class="p">()</span>
<span class="n">qaoa</span> <span class="o">=</span> <span class="n">QAOA</span><span class="p">(</span><span class="n">qubit_operators</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">operator_mode</span><span class="o">=</span><span class="s1">&#39;matrix&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here the choice of the classical optimizer <code class="docutils literal notranslate"><span class="pre">COBYLA</span></code> was arbitrary. Let us run this and analyze the solution. This can take a while on a classical simulator.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">backend</span> <span class="o">=</span> <span class="n">get_aer_backend</span><span class="p">(</span><span class="s1">&#39;statevector_simulator&#39;</span><span class="p">)</span>
<span class="n">quantum_instance</span> <span class="o">=</span> <span class="n">QuantumInstance</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span> <span class="n">shots</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">qaoa</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">quantum_instance</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">max_cut</span><span class="o">.</span><span class="n">sample_most_likely</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;eigvecs&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">graph_solution</span> <span class="o">=</span> <span class="n">max_cut</span><span class="o">.</span><span class="n">get_graph_solution</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;energy:&#39;</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;energy&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;maxcut objective:&#39;</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;energy&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">offset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;solution:&#39;</span><span class="p">,</span> <span class="n">max_cut</span><span class="o">.</span><span class="n">get_graph_solution</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;solution objective:&#39;</span><span class="p">,</span> <span class="n">max_cut</span><span class="o">.</span><span class="n">max_cut_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>energy: -0.8076121640957552
maxcut objective: -2.3045777105109226
solution: [0. 0. 1. 1.]
solution objective: 2.6693304526211796
</pre></div>
</div>
</div>
</div>
<p>Looking at the solution, the cut matches the clustering structure.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="solving-the-max-cut-problem-by-annealing">
<h1>Solving the max-cut problem by annealing<a class="headerlink" href="#solving-the-max-cut-problem-by-annealing" title="Permalink to this headline"></a></h1>
<p>Naturally, the same problem can be solved on an annealer. Our only task is to translate the couplings and the on-site fields to match the programming interface:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dimod</span>

<span class="n">J</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_instances</span><span class="p">):</span>
    <span class="n">h</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_instances</span><span class="p">):</span>
        <span class="n">J</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">dimod</span><span class="o">.</span><span class="n">BinaryQuadraticModel</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">dimod</span><span class="o">.</span><span class="n">SPIN</span><span class="p">)</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">dimod</span><span class="o">.</span><span class="n">SimulatedAnnealingSampler</span><span class="p">()</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_reads</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Energy of samples:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">solution</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">data</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Energy:&quot;</span><span class="p">,</span> <span class="n">solution</span><span class="o">.</span><span class="n">energy</span><span class="p">,</span> <span class="s2">&quot;Sample:&quot;</span><span class="p">,</span> <span class="n">solution</span><span class="o">.</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Energy of samples:
Energy: -2.344729812412025 Sample: {0: -1, 1: -1, 2: 1, 3: 1}
Energy: -2.344729812412025 Sample: {0: -1, 1: -1, 2: 1, 3: 1}
Energy: -2.344729812412025 Sample: {0: -1, 1: -1, 2: 1, 3: 1}
Energy: -2.344729812412025 Sample: {0: 1, 1: 1, 2: -1, 3: -1}
Energy: -2.344729812412025 Sample: {0: 1, 1: 1, 2: -1, 3: -1}
Energy: -2.344729812412025 Sample: {0: 1, 1: 1, 2: -1, 3: -1}
Energy: -2.344729812412025 Sample: {0: 1, 1: 1, 2: -1, 3: -1}
Energy: -2.344729812412025 Sample: {0: -1, 1: -1, 2: 1, 3: 1}
Energy: -2.344729812412025 Sample: {0: 1, 1: 1, 2: -1, 3: -1}
Energy: -2.344729812412025 Sample: {0: 1, 1: 1, 2: -1, 3: -1}
</pre></div>
</div>
</div>
</div>
<p>If you look at the first sample, you will see that the first five data instances belong to the same graph partition, matching the actual cluster.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h1>
<p>[1] Otterbach, J. S., Manenti, R., Alidoust, N., Bestwick, A., Block, M., Bloom, B., Caldwell, S., Didier, N., Fried, E. Schuyler, Hong, S., Karalekas, P., Osborn, C. B., Papageorge, A., Peterson, E. C., Prawiroatmodjo, G., Rubin, N., Ryan, Colm A., Scarabelli, D., Scheer, M., Sete, E. A., Sivarajah, P., Smith, Robert S., Staley, A., Tezak, N., Zeng, W. J., Hudson, A., Johnson, Blake R., Reagor, M., Silva, M. P. da, Rigetti, C. (2017). <a class="reference external" href="https://arxiv.org/abs/1712.05771">Unsupervised Machine Learning on a Hybrid Quantum Computer</a>. <em>arXiv:1712.05771</em>. <a id='1'></a></p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./qml/3_Classical_Quantum_Hybrid_Learning_Algorithms"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="3_1_Discrete_Optimization_And_Ensemble_Learning_Ecoding_Classical_Inforfmation_9.html" class="btn btn-neutral float-left" title="Encoding Classical Information" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="3_3_Kernel_Methods_11.html" class="btn btn-neutral float-right" title="Kernel Methods" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>